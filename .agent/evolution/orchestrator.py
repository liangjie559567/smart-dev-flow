"""
Evolution Orchestrator â€” è¿›åŒ–åè°ƒå™¨

æ•´åˆæ‰€æœ‰è¿›åŒ–å¼•æ“æ¨¡å—ï¼Œæä¾›ç»Ÿä¸€å…¥å£ï¼š
  - /evolve: å®Œæ•´è¿›åŒ–å‘¨æœŸ
  - /reflect: åæ€å·¥ä½œæµ
  - /knowledge: çŸ¥è¯†æŸ¥è¯¢
  - /patterns: æ¨¡å¼æŸ¥è¯¢

Usage:
    from evolution.orchestrator import EvolutionOrchestrator
    evo = EvolutionOrchestrator(base_dir=".agent/memory")
    report = evo.evolve()         # å®Œæ•´è¿›åŒ–
    evo.reflect(session_name=...) # åæ€
"""

from __future__ import annotations

import datetime
from pathlib import Path

from evolution.harvester import KnowledgeHarvester
from evolution.index_manager import KnowledgeIndexManager
from evolution.confidence import ConfidenceEngine
from evolution.reflection import ReflectionEngine
from evolution.pattern_detector import PatternDetector
from evolution.learning_queue import LearningQueue
from evolution.metrics import WorkflowMetrics


class EvolutionOrchestrator:
    """
    è¿›åŒ–å¼•æ“æ€»æ§åˆ¶å™¨ã€‚

    æ•´åˆäº”å¤§æ¨¡å—:
    1. Knowledge Harvester (çŸ¥è¯†æ”¶å‰²)
    2. Knowledge Index (ç´¢å¼•ç®¡ç†)
    3. Confidence Engine (ç½®ä¿¡åº¦ç®¡ç†)
    4. Reflection Engine (åæ€å¼•æ“)
    5. Pattern Detector (æ¨¡å¼æ£€æµ‹)
    6. Learning Queue (å­¦ä¹ é˜Ÿåˆ—)
    7. Workflow Metrics (å·¥ä½œæµæŒ‡æ ‡)
    """

    def __init__(self, base_dir: str | Path = ".agent/memory"):
        self.base_dir = Path(base_dir)
        self.harvester = KnowledgeHarvester(base_dir)
        self.index_mgr = KnowledgeIndexManager(base_dir)
        self.confidence = ConfidenceEngine(base_dir)
        self.reflection = ReflectionEngine(base_dir)
        self.pattern_detector = PatternDetector(base_dir)
        self.learning_queue = LearningQueue(base_dir)
        self.metrics = WorkflowMetrics(base_dir)

    # â”€â”€ /evolve â”€â”€

    def evolve(self) -> str:
        """
        æ‰§è¡Œå®Œæ•´è¿›åŒ–å‘¨æœŸã€‚

        Steps:
        1. å¤„ç†å­¦ä¹ é˜Ÿåˆ—
        2. é‡å»ºçŸ¥è¯†ç´¢å¼•
        3. è¿è¡Œ Confidence è¡°å‡
        4. æ£€æµ‹ä»£ç æ¨¡å¼
        5. åˆ†æå·¥ä½œæµæ•ˆèƒ½
        6. ç”Ÿæˆè¿›åŒ–æŠ¥å‘Š

        Returns
        -------
        str
            è¿›åŒ–æŠ¥å‘Š (Markdown)
        """
        today = datetime.date.today().isoformat()

        # Step 1: å¤„ç†å­¦ä¹ é˜Ÿåˆ—
        queue_stats = self.learning_queue.get_stats()
        processed = self.learning_queue.process_queue()

        # Step 2: é‡å»ºçŸ¥è¯†ç´¢å¼•
        self.index_mgr.rebuild_index()
        entries = self.harvester.list_entries()

        # Step 3: Confidence è¡°å‡
        decayed = self.confidence.decay_unused(days=30)
        deprecated = self.confidence.get_deprecated()

        # Step 4: æ¨¡å¼æ£€æµ‹
        pattern_result = self.pattern_detector.detect_and_update()

        # Step 5: å·¥ä½œæµæ´å¯Ÿ
        insights = self.metrics.get_all_insights()

        # Step 6: åæ€æ‘˜è¦
        reflection_summary = self.reflection.get_reflection_summary(5)
        pending_actions = self.reflection.get_pending_action_items()

        # Step 7: æ¸…ç†
        cleaned = self.learning_queue.cleanup(days=7)

        # ç”ŸæˆæŠ¥å‘Š
        report = self._generate_report(
            today=today,
            total_knowledge=len(entries),
            queue_processed=len(processed),
            queue_pending=queue_stats.get("pending", 0),
            decayed=decayed,
            deprecated=deprecated,
            pattern_result=pattern_result,
            insights=insights,
            reflection_summary=reflection_summary,
            pending_actions=pending_actions,
            cleaned=cleaned,
        )

        return report

    # â”€â”€ /reflect â”€â”€

    def reflect(
        self,
        session_name: str,
        duration: int = 0,
        went_well: list[str] | None = None,
        could_improve: list[str] | None = None,
        learnings: list[str] | None = None,
        action_items: list[str] | None = None,
        auto_fix_count: int = 0,
        rollback_count: int = 0,
    ) -> str:
        """æ‰§è¡Œåæ€å¹¶è¿”å›æŠ¥å‘Š"""
        report = self.reflection.reflect(
            session_name=session_name,
            duration=duration,
            went_well=went_well,
            could_improve=could_improve,
            learnings=learnings,
            action_items=action_items,
            auto_fix_count=auto_fix_count,
            rollback_count=rollback_count,
        )

        # å°†å­¦ä¹ æˆæœå…¥é˜Ÿ
        for learning in (learnings or []):
            self.learning_queue.add_item(
                source_type="conversation",
                source_id=f"reflect-{session_name}",
                priority="P2",
                description=learning,
            )

        return report.to_markdown()

    # â”€â”€ /knowledge â”€â”€

    def search_knowledge(self, query: str) -> list[dict]:
        """æœç´¢çŸ¥è¯†åº“"""
        return self.harvester.search(query)

    # â”€â”€ /patterns â”€â”€

    def search_patterns(self, query: str) -> list[dict]:
        """æœç´¢æ¨¡å¼åº“"""
        return self.pattern_detector.suggest_reuse(query)

    # â”€â”€ Task Lifecycle Hooks â”€â”€

    def on_task_completed(self, task_id: str, description: str = "") -> None:
        """ä»»åŠ¡å®Œæˆé’©å­: å…¥é˜Ÿå­¦ä¹ ç´ æ"""
        self.learning_queue.add_item(
            source_type="code_change",
            source_id=task_id,
            priority="P2",
            description=description,
        )

    def on_error_fixed(
        self, error_type: str, root_cause: str, solution: str
    ) -> None:
        """é”™è¯¯ä¿®å¤é’©å­: å…¥é˜Ÿå­¦ä¹ ç´ æ + ç›´æ¥ç”ŸæˆçŸ¥è¯†æ¡ç›®"""
        self.learning_queue.add_item(
            source_type="error_fix",
            source_id=f"fix-{error_type[:20]}",
            priority="P1",
            description=f"{error_type}: {root_cause}",
        )
        # ç›´æ¥æ”¶å‰²ä¸ºçŸ¥è¯†
        entry = self.harvester.harvest_from_error_fix(
            error_type=error_type,
            root_cause=root_cause,
            solution=solution,
        )
        # æ›´æ–°ç´¢å¼•
        self.index_mgr.add_to_index(
            kid=entry.id,
            title=entry.title,
            category=entry.category,
            confidence=entry.confidence,
            created=entry.created,
        )

    def on_workflow_completed(
        self,
        workflow: str,
        duration_min: int,
        success: bool = True,
        notes: str = "",
    ) -> None:
        """å·¥ä½œæµå®Œæˆé’©å­: è®°å½•æŒ‡æ ‡"""
        self.metrics.record_run(
            workflow=workflow,
            duration_min=duration_min,
            success=success,
            notes=notes,
        )

    # â”€â”€ Report Generation â”€â”€

    def _generate_report(
        self,
        today: str,
        total_knowledge: int,
        queue_processed: int,
        queue_pending: int,
        decayed: list,
        deprecated: list,
        pattern_result: dict,
        insights: dict,
        reflection_summary: str,
        pending_actions: list,
        cleaned: int,
    ) -> str:
        """ç”Ÿæˆè¿›åŒ–æŠ¥å‘Š"""
        lines = [
            f"# ğŸ§¬ Evolution Report â€” {today}",
            "",
            "## ğŸ“š Knowledge Updates",
            f"- **Total**: {total_knowledge} items",
            f"- **Decayed** (30d unused): {len(decayed)} items",
            f"- **Deprecated** (confidence < 0.5): {len(deprecated)} items",
        ]
        if deprecated:
            for d in deprecated:
                lines.append(f"  - {d['id']}: {d['title']} (conf: {d['confidence']})")

        lines += [
            "",
            "## ğŸ“¥ Learning Queue",
            f"- **Processed**: {queue_processed} items",
            f"- **Remaining**: {queue_pending} items",
            f"- **Cleaned** (7d old): {cleaned} items",
        ]

        lines += [
            "",
            "## ğŸ”„ Pattern Detection",
            f"- **Matches**: {len(pattern_result.get('matches', []))}",
            f"- **New Patterns**: {len(pattern_result.get('new_patterns', []))}",
            f"- **Promoted**: {len(pattern_result.get('promoted', []))}",
        ]
        for p in pattern_result.get("new_patterns", []):
            lines.append(f"  - NEW: {p}")
        for p in pattern_result.get("promoted", []):
            lines.append(f"  - PROMOTED: {p}")

        lines += [
            "",
            "## ğŸ“Š Workflow Insights",
            "| Workflow | Avg Duration | Success Rate | Runs | Bottleneck |",
            "|----------|--------------|--------------|------|------------|",
        ]
        for wf, insight in insights.items():
            if insight.total_runs > 0:
                lines.append(
                    f"| {wf} | {insight.avg_duration} min "
                    f"| {insight.success_rate:.0%} | {insight.total_runs} "
                    f"| {insight.common_bottleneck or 'N/A'} |"
                )
        if all(i.total_runs == 0 for i in insights.values()):
            lines.append("| - | - | - | - | æš‚æ— æ•°æ® |")

        # Suggestions
        suggestions = [i.suggestion for i in insights.values() if i.suggestion]
        if suggestions:
            lines += ["", "### Optimization Suggestions"]
            for i, s in enumerate(suggestions, 1):
                lines.append(f"{i}. {s}")

        lines += [
            "",
            "## ğŸ’­ Reflection Summary",
            reflection_summary,
            f"- **Pending Action Items**: {len(pending_actions)}",
        ]

        lines += [
            "",
            "## ğŸ¯ Recommended Next Steps",
        ]
        if pending_actions:
            for act in pending_actions[:5]:
                lines.append(f"1. {act}")
        else:
            lines.append("1. ç»§ç»­ç§¯ç´¯çŸ¥è¯†æ¡ç›®")
            lines.append("2. æ‰§è¡Œ `/reflect` åæ€æœ€è¿‘çš„å·¥ä½œ")

        lines += [
            "",
            "---",
            f"*Evolution Engine v1.0 | Total Knowledge: {total_knowledge} items "
            f"| Patterns: {len(pattern_result.get('matches', []))}*",
            "",
        ]

        return "\n".join(lines)
